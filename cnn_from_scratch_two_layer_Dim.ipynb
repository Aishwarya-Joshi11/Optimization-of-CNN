{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "class Conv3x3:\n",
    "    \n",
    "    def __init__(self, num_filters,f,n_c):\n",
    "        self.num_filters = num_filters\n",
    "        self.n_c = n_c\n",
    "        self.f = f\n",
    "        self.filters = np.random.normal(loc=0, scale=np.sqrt(1./(self.n_c*self.f*self.f)), size=(num_filters,self.n_c, self.f, self.f))\n",
    "        self.t_f = 0\n",
    "        \n",
    "    def forward(self, input):\n",
    "        \n",
    "        u = time.time()\n",
    "        \n",
    "        self.last_input = input\n",
    "    \n",
    "        h, w , n_c = input.shape\n",
    "        \n",
    "        \n",
    "        output = np.zeros((h - self.f+1, w - self.f+1, self.num_filters),dtype=np.float64)\n",
    "    \n",
    "        for i in range(h-self.f+1):\n",
    "            for j in range(w-self.f+1):\n",
    "                for k in range(self.num_filters):\n",
    "                    for n in range(self.n_c):\n",
    "                        \n",
    "                        temp = np.logical_and(input[i:i+self.f,j:j+self.f,n],self.filters[k,n,:,:])\n",
    "                        \n",
    "                        output[i, j , k] += np.sum(input[i:i+self.f,j:j+self.f,n][temp==True] * self.filters[k,n,:,:][temp==True])\n",
    "                            \n",
    "                output[i,j,k] = np.maximum(0,output[i,j,k])\n",
    "                    \n",
    "        self.last_output = output\n",
    "\n",
    "        v =  time.time()\n",
    "        \n",
    "        self.t_f += v-u\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def backprop(self, d_L_d_out, learn_rate):\n",
    "        \n",
    "        d_L_d_out[self.last_output<0] = 0\n",
    "        \n",
    "        d_L_d_filters = np.zeros(self.filters.shape,dtype=np.float64)\n",
    "    \n",
    "        h,w,c = self.last_input.shape\n",
    "        d_L_d_i = np.zeros((h,w,c))\n",
    "        for i in range(h-self.f+1):\n",
    "            for j in range(w-self.f+1):\n",
    "                  for f in range(self.num_filters):\n",
    "                        for n in range(self.n_c):\n",
    "                            d_L_d_filters[f,n,:,:] += d_L_d_out[i, j, f] * self.last_input[i:i+self.f,j:j+self.f,n]\n",
    "                            d_L_d_i[i:i+self.f,j:j+self.f,n] += d_L_d_out[i, j, f] * self.filters[f,n,:,:]\n",
    "                            \n",
    "        self.filters -= learn_rate * d_L_d_filters\n",
    "\n",
    "        return d_L_d_i\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class MaxPool2:\n",
    "    \n",
    "    def iterate_regions(self, image):\n",
    "        h, w, _ = image.shape\n",
    "        new_h = h // 2\n",
    "        new_w = w // 2\n",
    "    \n",
    "        for i in range(new_h):\n",
    "            for j in range(new_w):\n",
    "                im_region = image[(i * 2):(i * 2 + 2), (j * 2):(j * 2 + 2)]\n",
    "                yield im_region, i, j\n",
    "    \n",
    "    def forward(self, input):\n",
    "    \n",
    "        self.last_input = input\n",
    "\n",
    "        h, w, num_filters = input.shape\n",
    "        output = np.zeros((h // 2, w // 2, num_filters))\n",
    "\n",
    "        for im_region, i, j in self.iterate_regions(input):\n",
    "            output[i, j] = np.amax(im_region, axis=(0, 1))\n",
    "\n",
    "        return output\n",
    "\n",
    "    def backprop(self, d_L_d_out):\n",
    "       \n",
    "        d_L_d_input = np.zeros(self.last_input.shape)\n",
    "\n",
    "        for im_region, i, j in self.iterate_regions(self.last_input):\n",
    "            h, w, f = im_region.shape\n",
    "            amax = np.amax(im_region, axis=(0, 1))\n",
    "\n",
    "            for i2 in range(h):\n",
    "                for j2 in range(w):\n",
    "                      for f2 in range(f):\n",
    "                        # If this pixel was the max value, copy the gradient to it.\n",
    "                            if im_region[i2, j2, f2] == amax[f2]:\n",
    "                                  d_L_d_input[i * 2 + i2, j * 2 + j2, f2] = d_L_d_out[i, j, f2]\n",
    "\n",
    "        return d_L_d_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Softmax:\n",
    "\n",
    "    def __init__(self, input_len, nodes):\n",
    "        self.weights = np.random.normal(loc=0, scale=np.sqrt(1./(input_len*nodes)), size=(input_len,nodes))\n",
    "\n",
    "        self.biases = np.random.normal(loc=0, scale=np.sqrt(1./(nodes)), size=(nodes))\n",
    "\n",
    "    def forward(self, input):\n",
    "        \n",
    "        \n",
    "        self.last_input_shape = input.shape\n",
    "\n",
    "        input = input.flatten()\n",
    "        \n",
    "        self.last_input = input\n",
    "\n",
    "        input_len, nodes = self.weights.shape[0],self.weights.shape[1]\n",
    "\n",
    "        totals = np.dot(input, self.weights) + self.biases\n",
    "        \n",
    "        totals -= np.max(totals)\n",
    "        \n",
    "        self.last_totals = totals\n",
    "\n",
    "        exp = np.exp(totals,dtype=np.float64)\n",
    "        \n",
    "        return exp / np.sum(exp, axis=0)\n",
    "\n",
    "    def backprop(self, d_L_d_out, learn_rate):\n",
    "        \n",
    "        for i, gradient in enumerate(d_L_d_out):\n",
    "            if gradient == 0:\n",
    "                continue\n",
    "\n",
    "            t_exp = np.exp(self.last_totals)\n",
    "\n",
    "            S = np.sum(t_exp)\n",
    "\n",
    "            d_out_d_t = -t_exp[i] * t_exp / (S ** 2)\n",
    "            d_out_d_t[i] = t_exp[i] * (S - t_exp[i]) / (S ** 2)\n",
    "            \n",
    "            d_t_d_w = self.last_input\n",
    "            d_t_d_b = 1\n",
    "            d_t_d_inputs = self.weights\n",
    "\n",
    "            d_L_d_t = gradient * d_out_d_t\n",
    "\n",
    "            d_L_d_w = d_t_d_w[np.newaxis].T @ d_L_d_t[np.newaxis]\n",
    "            d_L_d_b = d_L_d_t * d_t_d_b\n",
    "            d_L_d_inputs = d_t_d_inputs @ d_L_d_t\n",
    "\n",
    "            self.weights -= learn_rate * d_L_d_w\n",
    "            self.biases -= learn_rate * d_L_d_b\n",
    "\n",
    "            return d_L_d_inputs.reshape(self.last_input_shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda31\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "\n",
    "\n",
    "train_images = np.zeros([400,28,28,1])\n",
    "test_images = np.zeros([100,28,28,1])\n",
    "\n",
    "(images_tr, train_labels), (images_ts1, test_labels) = mnist.load_data()\n",
    "\n",
    "images_tr = np.array(images_tr[:400])\n",
    "train_labels = np.array(train_labels[:400])\n",
    "    \n",
    "images_ts = np.array(images_ts1[:100])\n",
    "test_labels = np.array(test_labels[0:100])\n",
    "\n",
    "\n",
    "for i in range(400):\n",
    "    train_images[i] = images_tr[i].reshape(28,28,1) \n",
    "    \n",
    "for i in range(100):    \n",
    "    test_images[i] = images_ts[i].reshape(28,28,1)\n",
    "    \n",
    "#print(train_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training_data:   0%|▎                                                                  | 2/400 [00:00<00:30, 13.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Epoch 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training_data:   0%|▎                                                                  | 2/400 [00:00<00:35, 11.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after epoch1 loss is 2.1371514753066414 accuracy is 0.3225\n",
      "\n",
      "\n",
      "--- Epoch 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training_data:   0%|                                                                           | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after epoch2 loss is 1.5683861670699781 accuracy is 0.6125\n",
      "\n",
      "\n",
      "--- Epoch 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_data:   2%|█▍                                                                     | 2/100 [00:00<00:05, 17.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after epoch3 loss is 0.7721954664608355 accuracy is 0.785\n",
      "Testing on test data set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_data: 100%|█████████████████████████████████████████████████████████████████████| 100/100 [00:11<00:00,  8.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on test dataset: 0.5923286608955951\n",
      "Accuracy on test dataset: 0.82\n",
      "\n",
      "\n",
      "total time taken is  293.6001307964325\n",
      "total time taken for conv forward prop is  134.80283522605896\n"
     ]
    }
   ],
   "source": [
    "import mnist\n",
    "import numpy as np\n",
    "import tqdm as tqdm\n",
    "\n",
    "conv1 = Conv3x3(8,3,1)\n",
    "pool1 = MaxPool2()                  \n",
    "\n",
    "conv2 = Conv3x3(8,3,1)\n",
    "pool2 = MaxPool2()                  \n",
    "\n",
    "softmax = Softmax(200, 10) \n",
    "\n",
    "def forward(image, label): \n",
    "    \n",
    "    out = conv1.forward((image/255) )\n",
    "    out = pool1.forward(out)\n",
    "    \n",
    "    out = conv2.forward(out)\n",
    "    out = pool2.forward(out)\n",
    "    \n",
    "    out = softmax.forward(out)\n",
    "    \n",
    "    if out[label] == 0:\n",
    "        out[label] = sys.float_info.min\n",
    "    \n",
    "    \n",
    "    loss = -np.log(out[label])\n",
    "    acc = 1 if np.argmax(out) == label else 0\n",
    "\n",
    "    return out, loss, acc\n",
    "\n",
    "def train(im, label, lr=.005):\n",
    "   \n",
    "    out, loss, acc = forward(im, label)\n",
    "\n",
    "    gradient = np.zeros(10)\n",
    "    if out[label] == 0:\n",
    "        out[label] = sys.float_info.min\n",
    "    gradient[label] = -1 / out[label]\n",
    "\n",
    "    gradient = softmax.backprop(gradient, lr)\n",
    "    gradient = pool2.backprop(gradient)\n",
    "    gradient = conv2.backprop(gradient, lr)\n",
    "    gradient = pool1.backprop(gradient)\n",
    "    gradient = conv1.backprop(gradient, lr)\n",
    "    \n",
    "    return loss, acc\n",
    "\n",
    "t1 = time.time()\n",
    "for epoch in range(3):\n",
    "#     break\n",
    "    print('\\n')\n",
    "    print('--- Epoch %d ---' % (epoch + 1))\n",
    "\n",
    "    permutation = np.random.permutation(len(train_images))\n",
    "    train_images = train_images[permutation]\n",
    "    train_labels = train_labels[permutation]\n",
    "    \n",
    "    loss = 0\n",
    "    num_correct = 0\n",
    "    outer = tqdm.tqdm(total=len(train_images), desc='training_data', position=0)\n",
    "    \n",
    "    for i, (im, label) in enumerate(zip(train_images, train_labels)):\n",
    "        outer.update(1)\n",
    "        l, acc = train(im, label)\n",
    "        loss += l\n",
    "        num_correct += acc\n",
    "        \n",
    "        \n",
    "        \n",
    "    print('after epoch' + str(epoch+1) + ' loss is ' + str(loss/len(train_images)) + ' accuracy is ' + str(num_correct/len(train_images)))\n",
    "    \n",
    "    \n",
    "t2 = time.time()\n",
    "\n",
    "total_time = t2-t1\n",
    "\n",
    "total_time_conv = conv1.t_f + conv2.t_f \n",
    "        \n",
    "        \n",
    "print('Testing on test data set')\n",
    "loss = 0\n",
    "num_correct = 0\n",
    "\n",
    "test = tqdm.tqdm(total=len(test_images), desc='test_data', position=0)\n",
    "    \n",
    "for im, label in zip(test_images, test_labels):\n",
    "    test.update(1)\n",
    "    _, l, acc = forward(im, label)\n",
    "    loss += l\n",
    "    num_correct += acc\n",
    "\n",
    "\n",
    "\n",
    "num_tests = len(test_images)\n",
    "print('Loss on test dataset:', loss / num_tests)\n",
    "print('Accuracy on test dataset:', num_correct / num_tests)\n",
    "print('\\n')\n",
    "print('total time taken is ',total_time)\n",
    "print('total time taken for conv forward prop is ',total_time_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore the below blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test cases: \n",
      "\n",
      " \n",
      "\n",
      "\n",
      "input image :\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " predicted Output"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'input'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-b8aeba538ff9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" predicted Output\"\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict_out\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-b8aeba538ff9>\u001b[0m in \u001b[0;36mpredict_out\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpool1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSoftmax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'input'"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow, show\n",
    "\n",
    "def predict_out(image):\n",
    "    \n",
    "    out = conv1.forward((image / 255) - 0.5)\n",
    "    out = pool1.forward(out)\n",
    "    out = Softmax.forward(out)\n",
    "    \n",
    "    return np.argmax(out)\n",
    "\n",
    "\n",
    "\n",
    "print(\"test cases: \\n\\n \")\n",
    "\n",
    "for j in range(7):\n",
    "    rand = randint(1000,2000)\n",
    "    print(\"\\n\\ninput image :\")\n",
    "    test_img = np.array(images_ts1[rand]).reshape(28,28)\n",
    "    imshow(test_img)\n",
    "    show()\n",
    "    \n",
    "    print(\" predicted Output\" , end = \"\")\n",
    "    print(predict_out(test_img.reshape(28,28,1)))\n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
